---
type: lecture
date: 2024-11-07
title: Efficient Pretraining with Sparse Models
module: Scaling up language models
hide_from_announcments: true
links: 
 - url: coming soon
   name: slides
---
Suggested Readings:
 - [Review of MoE](https://arxiv.org/abs/2209.01667)
 - [Switch Transformer](https://arxiv.org/abs/2101.03961)
 - [MatFormer](https://arxiv.org/pdf/2310.07707)
